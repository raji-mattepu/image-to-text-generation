# -*- coding: utf-8 -*
"""image_to_txt_gen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AWBM-CRETZsPoYNif-FmrYNRZ-OVObFx
"""

!pip install gTTS
!pip install transformers
!pip install torch
!pip install textblob



import requests
from PIL import Image
from transformers import AutoProcessor, AutoModelForCausalLM
import torch
from textblob import TextBlob
import os
from gtts import gTTS
from IPython.display import Audio
import matplotlib.pyplot as plt


def download_image(url):
    response = requests.get(url)
    image = Image.open(requests.get(url, stream=True).raw)
    plt.imshow(image)
    plt.axis('off')  # Hide axes
    plt.show()
    return image

def generate_description(image):
    processor = AutoProcessor.from_pretrained("microsoft/git-base-coco")
    model = AutoModelForCausalLM.from_pretrained("microsoft/git-base-coco")

    inputs = processor(images=image, return_tensors="pt")

    with torch.no_grad():
        # Generate more descriptive captions by adjusting parameters
        generated_ids = model.generate(
            pixel_values=inputs["pixel_values"],
            max_length=1000,           # Increase the max length for more detailed descriptions
            num_beams=5,              # Use beam search with more beams to explore more possible captions
            repetition_penalty=1.0,   # Penalize repetitions for more diverse output
            no_repeat_ngram_size=2,   # Avoid repeating bigrams
            early_stopping=True       # Stop early if all beams reach the end
        )

    generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
    return generated_caption

def analyze_emotion(text):
    analysis = TextBlob(text)
    polarity = analysis.sentiment.polarity

    if polarity > 0.1:
        return "happy"
    elif polarity < -0.1:
        return "sad"
    else:
        return "neutral"

def text_to_speech(description, output_file="output.mp3", lang='en'):
    tts = gTTS(text=description , lang=lang)
    tts.save(output_file)
    print(f"Audio saved as {output_file}")

def main():
    image_url = input("Enter the image URL: ")

    try:
        image = download_image(image_url)
        description = generate_description(image)
        emotion = analyze_emotion(description)
        text_to_speech(description)

        print(f"Generated description: {description}")
        print(f"Emotional tone: {emotion}")

    except Exception as e:
        print(f"An error occurred: {str(e)}")



if __name__ == "__main__":
  main()
Audio("output.mp3", autoplay=True)

